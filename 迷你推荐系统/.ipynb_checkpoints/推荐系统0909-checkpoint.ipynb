{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于协同过滤算法的电影推荐系统"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "一、准备数据集\n",
    "   这一次用到的数据集还是来自于movielen的数据，用到的是ml-100k的数据集，官网上有很多版本，主要区别在于数据量大小而已。有兴趣的小伙伴可以采用更大的数据集去做实验！先来看看数据长什么样子吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only single character unicode strings can be converted to Py_UCS4, got length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c1fbf17592ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0muser_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./u.data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmovie_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./u.item.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0muser_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./u.data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: only single character unicode strings can be converted to Py_UCS4, got length 0"
     ]
    }
   ],
   "source": [
    "#导入需要用到的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "user_file=pd.read_csv('./u.data')\n",
    "movie_file=pd.read_csv('./u.item.txt',sep='|')\n",
    "\n",
    "user_df = pd.read_csv('./u.data',sep='\\t',names=['user_id','item_id','rating','timestamp'])\n",
    "movies_df = pd.read_csv('./u.item.txt',encoding='utf-8',sep='|',usecols=['movie_id','movie_title' ,\n",
    "                                                                            'release date'],\n",
    "                                                                              names=['movie_id','movie_title' ,\n",
    "                                                                            'release date','video release date',\n",
    "                                                                            'IMDb URL','unknown','Action','Adventure',\n",
    "                                                                            'Animation','Children','Comedy','Crime',\n",
    "                                                                            'Documentary','Drama','Fantasy','Film-Noir',\n",
    "                                                                            'Horror','Musical','Mystery',' Romance',\n",
    "                                                                            'Sci-Fi','Thriller','War','Western'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看用户点评数据\n",
    "user_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看电影数据\n",
    "movies_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df[movies_df['movie_title'].str.contains('Mission')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[movies_df['movie_title'].str.contains('Trans')]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "因为只用到这两份文件，所以其它的不做一一展示了，有兴趣可以试一下其它文件。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "二、协同过滤\n",
    "      协同过滤方法可以分为两个主要部分：基于用户协同过滤和产品-产品协同过滤。一个基于用户协同过滤将选取一个特定的用户，基于打分的相似性发现类似于该用户的用户，并推荐那些相似用户喜欢的产品。\n",
    "      相比之下，基于产品协同过滤会选取一个产品，发现喜欢该产品的用户，并找到这些用户或相似的用户还喜欢的其他的产品。输入一个产品，然后输出其他产品作为荐。简单来说，就是：\n",
    "    基于用户协同过滤: “喜欢这个东西的人也喜欢……”\n",
    "    基于产品协同过滤: “像你一样的人也喜欢……” \n",
    "    其中有一个关键点，就是计算相似度。这里将要用到的方法是余弦相似度，类似的还有欧几里得距离，曼哈顿距离等等来衡量两者之间的距离（相似性）。但在这里，协同过滤用余弦相似度要更好，也更合理。因为也有现成的函数可以使用，所以就不详细说明了。原理的话可以自己查找一下资料，还是容易理解的，涉及到一点线性代数知识。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "我们就一步步来构造这个基于协同过滤的的小电影推荐系统！"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3.1 构造用户-电影矩阵\n",
    "    协同过滤就设计到两点：用户-物品矩阵，相似度。我们先来构造第一个，有上面的df表，可以看到user_id（用户），item_id（电影），rating（评分）三个维度，刚好就是我们想要的，于是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = user_df.user_id.unique().shape[0]       #用户总数\n",
    "n_items = user_df.item_id.unique().shape[0]        #电影总数\n",
    "data_matrix = np.zeros((n_users,n_items))     #矩阵\n",
    "for line in user_df.itertuples():               \n",
    "    data_matrix[line[1]-1, line[2]-1] = line[3] \n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "每一行代表一个用户，每一列代表一部电影，矩阵元素则是评分。那接下来就可以进行第二步了——相似度计算。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3计算相似度计算\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    " #电影余弦相似度矩阵\n",
    "item_similarity=cosine_similarity(data_matrix.T, dense_output=True)     \n",
    "item_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推荐系统算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def movie_recsys(keywords,k):         #keywords：电影名关键词，k：为最接近的k部电影\n",
    "    keywords=keywords.title() \n",
    "    movie_list=[]       #存储结果列表\n",
    "    try:\n",
    "        #过滤电影数据集，搜索找到对应的电影的id\n",
    "        movieid=list(movies_df[movies_df['movie_title'].str.contains(keywords)].movie_id)[0]   \n",
    "        #获取该电影的余弦相似度数组\n",
    "        movie_similarity=item_similarity[movieid-1] \n",
    "        #返回前K+1个最高相似度的索引位置\n",
    "        movie_similarity_index=np.argsort(-movie_similarity)[:k+1]   \n",
    "        \n",
    "\n",
    "        for i in movie_similarity_index:\n",
    "            rec_movies=list(item_df[item_df.movie_id==(i+1)].movie_title)   #存储电影名\n",
    "            rec_movies.append(movie_similarity[i])                          #存储相似度\n",
    "            rec_movies.append(len(df[df.item_id==(i+1)]))                   #用户数\n",
    "            rec_movies.append(df[df.item_id==(i+1)]['rating'].mean())       #平均评分分\n",
    "            movie_list.append(rec_movies)                                  #列表中的元素为列表\n",
    "    except:\n",
    "        print('提示：找不到该电影！请检查输入！')\n",
    "    return movie_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    name=input('请输入电影名称或者关键词：')\n",
    "    num=int(input('您希望找到多少部相关电影（请输入整数）：'))\n",
    "    result=movie_recsys(name,num)\n",
    "    movieid=list(movies_df[movies_df['movie_title']==result[0][0]].movie_id)[0]\n",
    "    choice=input('是否设置相似度阈值（y/n）')\n",
    "    if choice=='y':\n",
    "        threshold=float(input('请设置一个阈值（0到1之间，该值越高电影间相似性越高）：'))\n",
    "        counter=0\n",
    "        for i in range(1,num+1):\n",
    "            if result[i][1]>=threshold:\n",
    "                counter+=1\n",
    "                \n",
    "        if counter==0:\n",
    "            print('抱歉，找不到符合条件的电影，可能阈值设置过高，请重新设置！')\n",
    "        else:\n",
    "            print('{}共有{}个用户评分,平均评分为{}(评分上限为5分)'.format(result[0][0],len(user_df[user_df.item_id==movieid]),\n",
    "                                                          \"%.5f\" %user_df[user_df.item_id==movieid]['rating'].mean()))\n",
    "                                                                  \n",
    "            print('经过阈值处理，与{}最相似的前{}部是（剔除了{}部）：'.format(result[0][0],counter,num-counter))\n",
    "            print()\n",
    "            for i in range(1,counter+1):\n",
    "                print(result[i][0],',相似度为:{}, 共有{}个用户评分，平均评分为{}(评分上限为5分)'.format(\n",
    "                                                                            \"%.6f\" %result[i][1],\n",
    "                                                                               result[i][2],\n",
    "                                                                          \"%.5f\" %result[i][3]))\n",
    "                \n",
    "    else:\n",
    "        print('{}共有{}个用户评分，平均评分为{}(评分上限为5分)'.format(result[0][0],len(user_df[user_df.item_id==movieid]),\n",
    "                                                            \"%.5f\" %user_df[user_df.item_id==movieid]['rating'].mean()))\n",
    "        print('与{}最相似的前{}部是：'.format(result[0][0],num))\n",
    "        print()\n",
    "        for i in range(1,num+1):\n",
    "            print(result[i][0],',相似度为:{}, 共有{}个用户评分，平均评分为{}(评分上限为5分)'.format(\n",
    "                                                                                    \"%.6f\" % result[i][1],\n",
    "                                                                                       result[i][2],\n",
    "                                                                                  \"%.5f\" % result[i][3]))\n",
    "\n",
    "    c=input('是否继续使用？（y/n）：')\n",
    "    if c=='y':\n",
    "        main() \n",
    "    else:\n",
    "        print('谢谢使用！')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
